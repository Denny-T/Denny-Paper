\documentclass[twocolumn]{article}
\usepackage{indentfirst}

\begin{document}

\title{A Memory-Efficient Parallel Name Lookup Model on NDN}
\author{Denny}
\date{}
\maketitle
%Abstract will be added later.
\begin{abstract}
\end{abstract}

\section{Introduction}
Named Lookup Network(NDN)[1], which is formerly known as Content-Centric Networking, has been recently proposed as a clean slate network architecture for future Internet. Different from the current network practice, it concentrates on the content itseft("what"), rather than "where" information is located. In NDN scenario,every distinct content/entity is referenced by a  unique name instead of an IP address for hardware device attached to IP network. Accordingly, communication in NDN is no longer address-based, but name-based. Compared with fixed length IP address, a content name could be much longer and more complex. Therefore, routing tables in NDN can be orders of magnitude larger than current IP routing tables.

Despite of its novelty, NDN operations can be grounded in current practice, routing and forwarding  of NDN network are semantically the same as that of IP network. One important fact is that NDN name lookup complies with longest prefix matching(LPM) and backbone NDN routers can have large-scale forwarding tables. In consideration of strict requirements on memory occupation, throughput, latency and fast incremental updates, practical name lookup engine design calls for elaborate design-level innovation.

\subsection{Package Forwarding in NDN}
In NDN, content naming is hierarchically structured and composed of explicitly delimited components, while the delimiters, usually slash('/'), are not part of a name. For instance, a video service provided by Youtube has the name \textit{/com/youtube/videos}, and \textit{com}, \textit{youtube} and \textit{videos} are there components of  the name.

%Fig1. to be added.

communications in NDN are driven by the data requesters. For example in Fig.1, a data requester(Host1) sends out an \textit{Interest} packet with a desired content name. Then Router A fowards the  Interest packet by looking up its name in the \textit{Forwarding Information Base(FIB)}. When the Interest packet reaches a node(Router B) that has the required data, a \textit{Data} packet is sent back to the requester(Host1). In practice, there will be two more cache lists, which are \textit{Content Store(CS)} and \textit{Pending Interest Table(PIT)} respectively. CS caches the data that has been forwarded by the router, while PIT contains information of requirements that have been forwarded to upstream but the response Data does not arrive yet. Generally, once an Interest reached a router, the router searches the request name in the CS first, then go to PIT if it fails to match in CS. In case that the lookup fails on both CS and PIT, it will continue on FIB.

\subsection{Prior Arts and Challenges}
To implement NDN routing with large-scale FIB tables in high speed networks, a core challenge and enabling technique is to perform content name lookup forwarding packet at wire speed. With the purpose of conquering the challenge, a GPU-based approach[] has been recently proposed. It designed a MATA data structure to store the FIB trie and employed data interweaving technique for optimizing the storage of input names in GPU memory. On average, it obtains a high lookup throughput, but for some special groups of long names, it could be impractical. Besides, there could be pressure to store FIB table as it increases rapidly.

Split Routing Lookup Model provides a solution to reduce FIB size in current IP network. In this model,

\subsection{Our Work}



\end{document}

